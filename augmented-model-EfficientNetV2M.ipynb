{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl72aPKJ7E9k"
      },
      "source": [
        "Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSGlWJNE7E9p",
        "outputId": "6144d64d-f5db-441f-c8d7-d0f2d0a42cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "seed = int(time.time())\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0YZYSShwxm4",
        "outputId": "3447b81c-e79d-41f5-e72f-15f3ee711bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "os.chdir('/gdrive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyQqDVXM7E9s"
      },
      "source": [
        "Data Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rWHmEC07E9t",
        "outputId": "44e12498-fa7b-4467-d216-4c2c24db1a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "healthy      3101\n",
            "unhealthy    1903\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "leafs_data = np.load(\"new_public_data.npz\", allow_pickle=True)\n",
        "data_leafs = np.array(leafs_data[\"array1\"]).astype(int)\n",
        "labels = np.array(leafs_data['array2'])\n",
        "\n",
        "print((pd.DataFrame(labels)).value_counts())\n",
        "labels = pd.DataFrame(labels)\n",
        "labels.describe()\n",
        "# Turning the classes into a binary coding 00:Unhealthy, 01:Healthy\n",
        "unique = labels.iloc[: , 0].unique()\n",
        "\n",
        "loc = [1,2]\n",
        "for pos in zip(loc , unique):\n",
        "    labels.insert(pos[0] , pos[1] , pos[0] - 1)\n",
        "\n",
        "labels_1 = labels\n",
        "labels_1.loc[labels[0] == 'healthy' , 'healthy'] = 1\n",
        "labels_1.loc[labels[0] == 'healthy', 'unhealthy'] = 0\n",
        "labels = labels_1\n",
        "labels = labels.drop(columns = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QAm32gu7E9u"
      },
      "source": [
        "labels_leafs = np.expand_dims(labels_leafs, axis=-1)\n",
        "values_leafs = np.array([])\n",
        "num = 0\n",
        "for i in labels_leafs:\n",
        "  if i == \"healthy\":\n",
        "    values_leafs = np.append(values_leafs, [0])\n",
        "  else:\n",
        "    values_leafs = np.append(values_leafs, [1])\n",
        "values_leafs = np.expand_dims(values_leafs, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZizsZgpj7E9u"
      },
      "outputs": [],
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    data_leafs,\n",
        "    labels,\n",
        "    test_size = 0.1,\n",
        "    random_state=seed,\n",
        "    stratify= labels\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val,\n",
        "    y_train_val,\n",
        "    test_size = len(X_test), # Ensure validation set size matches test set size\n",
        "    random_state=seed,\n",
        "    stratify= y_train_val\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5sc32Ma7E9v"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1]\n",
        "batch_size = 64\n",
        "epochs = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Zs5VrS71WG",
        "outputId": "ac976650-4953-4497-8c13-71a41a3ea3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
            "214201816/214201816 [==============================] - 6s 0us/step\n",
            "Model: \"V2B3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " augmentation (Sequential)   (None, 96, 96, 3)         0         \n",
            "                                                                 \n",
            " efficientnetv2-m (Function  (None, 1280)              53150388  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 16)                20496     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 16)                64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53170982 (202.83 MB)\n",
            "Trainable params: 20562 (80.32 KB)\n",
            "Non-trainable params: 53150420 (202.75 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_V2M(input_shape, output_shape, dropout_rate, seed=seed):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    augmentation = tf.keras.Sequential([\n",
        "        tfkl.RandomFlip(\"horizontal\", seed=seed),\n",
        "        tfkl.RandomFlip(\"vertical\", seed=seed),\n",
        "        tfkl.RandomBrightness(0.3, value_range=(0,255), seed=seed),\n",
        "        tfkl.RandomContrast(0.3, seed=seed),\n",
        "        tfkl.RandomZoom((0.2, 0.2), seed=seed),\n",
        "        tfkl.RandomTranslation(0.2, 0.2, seed=seed)\n",
        "    ], name='augmentation')\n",
        "\n",
        "    V2M = tfk.applications.EfficientNetV2M(\n",
        "        input_shape = input_shape,\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        pooling='avg',\n",
        "    )\n",
        "    V2M.trainable = False\n",
        "\n",
        "    input_layer = tfk.Input(shape=input_shape)\n",
        "\n",
        "    x = augmentation(input_layer)\n",
        "    x = V2M(x, training=False)\n",
        "\n",
        "    dropout = tfkl.Dropout(\n",
        "        dropout_rate,\n",
        "        seed=seed\n",
        "    )(x)\n",
        "\n",
        "    classifier_layer = tfkl.Dense(\n",
        "        units=16,\n",
        "        activation='relu',\n",
        "        name='dense1'\n",
        "    )(dropout)\n",
        "\n",
        "    dropout = tfkl.Dropout(\n",
        "        dropout_rate,\n",
        "        seed=seed\n",
        "    )(classifier_layer)\n",
        "\n",
        "    BCL = tfkl.BatchNormalization(\n",
        "\n",
        "    )(dropout)\n",
        "\n",
        "    output_layer = tfkl.Dense(\n",
        "        units=output_shape,\n",
        "        activation='sigmoid',\n",
        "        name='dense2'\n",
        "    )(BCL)\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='V2B3')\n",
        "\n",
        "    model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tl_model = build_V2M(input_shape, output_shape, 0.5)\n",
        "tl_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u7BHKB_7j5-"
      },
      "outputs": [],
      "source": [
        "patience=20\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, mode='max', restore_best_weights=True)\n",
        "lr_patience = 10\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',# Metric to monitor (validation mean squared error in this case)\n",
        "    patience=lr_patience,   # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    factor=0.1,            # Factor by which the learning rate will be reduced (0.999 in this case)\n",
        "    mode='max',            # Mode to decide when to reduce learning rate ('min' means reduce when metric stops decreasing)\n",
        "    min_lr=1e-5            # Minimum learning rate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ebfl4cQ7j5-",
        "outputId": "584ff78a-810f-41ad-ac36-c4fdd83590e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "63/63 [==============================] - 38s 162ms/step - loss: 0.7742 - accuracy: 0.5577 - val_loss: 0.6365 - val_accuracy: 0.6387 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.6816 - accuracy: 0.6394 - val_loss: 0.6143 - val_accuracy: 0.7106 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.6349 - accuracy: 0.6667 - val_loss: 0.6078 - val_accuracy: 0.6826 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.6023 - accuracy: 0.6867 - val_loss: 0.5703 - val_accuracy: 0.7405 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5948 - accuracy: 0.6899 - val_loss: 0.5540 - val_accuracy: 0.7385 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.5931 - accuracy: 0.6924 - val_loss: 0.5464 - val_accuracy: 0.7505 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5745 - accuracy: 0.6979 - val_loss: 0.5439 - val_accuracy: 0.7505 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.5661 - accuracy: 0.7111 - val_loss: 0.5340 - val_accuracy: 0.7605 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5659 - accuracy: 0.7091 - val_loss: 0.5352 - val_accuracy: 0.7485 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5643 - accuracy: 0.7081 - val_loss: 0.5323 - val_accuracy: 0.7605 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5725 - accuracy: 0.7094 - val_loss: 0.5323 - val_accuracy: 0.7505 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.5618 - accuracy: 0.7159 - val_loss: 0.5166 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5605 - accuracy: 0.7116 - val_loss: 0.5172 - val_accuracy: 0.7705 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.5617 - accuracy: 0.7164 - val_loss: 0.5238 - val_accuracy: 0.7844 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "63/63 [==============================] - 4s 71ms/step - loss: 0.5607 - accuracy: 0.7056 - val_loss: 0.5137 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5594 - accuracy: 0.7124 - val_loss: 0.5138 - val_accuracy: 0.7665 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5498 - accuracy: 0.7221 - val_loss: 0.5069 - val_accuracy: 0.7725 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5573 - accuracy: 0.7079 - val_loss: 0.5105 - val_accuracy: 0.7944 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.5551 - accuracy: 0.7166 - val_loss: 0.5010 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5629 - accuracy: 0.7139 - val_loss: 0.5177 - val_accuracy: 0.7505 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.5580 - accuracy: 0.7209 - val_loss: 0.4860 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.5520 - accuracy: 0.7211 - val_loss: 0.5024 - val_accuracy: 0.7784 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.5509 - accuracy: 0.7274 - val_loss: 0.4932 - val_accuracy: 0.7864 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5506 - accuracy: 0.7176 - val_loss: 0.4900 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5584 - accuracy: 0.7181 - val_loss: 0.4904 - val_accuracy: 0.7964 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5492 - accuracy: 0.7159 - val_loss: 0.4912 - val_accuracy: 0.7864 - lr: 1.0000e-04\n",
            "Epoch 27/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5545 - accuracy: 0.7159 - val_loss: 0.4910 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
            "Epoch 28/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5526 - accuracy: 0.7209 - val_loss: 0.4926 - val_accuracy: 0.7884 - lr: 1.0000e-04\n",
            "Epoch 29/300\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.5444 - accuracy: 0.7249 - val_loss: 0.4921 - val_accuracy: 0.7924 - lr: 1.0000e-04\n",
            "Epoch 30/300\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.5433 - accuracy: 0.7261 - val_loss: 0.4903 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
            "Epoch 31/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5457 - accuracy: 0.7206 - val_loss: 0.4904 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
            "Epoch 32/300\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.5483 - accuracy: 0.7141 - val_loss: 0.4908 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
            "Epoch 33/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5416 - accuracy: 0.7261 - val_loss: 0.4901 - val_accuracy: 0.7924 - lr: 1.0000e-04\n",
            "Epoch 34/300\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.5534 - accuracy: 0.7136 - val_loss: 0.4903 - val_accuracy: 0.7844 - lr: 1.0000e-04\n",
            "Epoch 35/300\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.5592 - accuracy: 0.7166 - val_loss: 0.4924 - val_accuracy: 0.7864 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history = tl_model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "RdPHteH97j5-",
        "outputId": "2938a0e2-fdef-4269-ab63-b97a8a60580c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions Shape: (501, 2)\n",
            "Accuracy: 0.7565\n",
            "Precision: 0.7465\n",
            "Recall: 0.7248\n",
            "F1: 0.7314\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions = tl_model.predict(X_test, verbose=0)\n",
        "print(\"Predictions Shape:\", predictions.shape)\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1))\n",
        "\n",
        "# Compute classification metrics\n",
        "accuracy = accuracy_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1))\n",
        "precision = precision_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "recall = recall_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "f1 = f1_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "\n",
        "# Display the computed metrics\n",
        "print('Accuracy:', accuracy.round(4))\n",
        "print('Precision:', precision.round(4))\n",
        "print('Recall:', recall.round(4))\n",
        "print('F1:', f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm.T, xticklabels={0, 1}, yticklabels={0, 1}, cmap='Blues')\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QpwXksX7vmK"
      },
      "source": [
        "Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ogW98aN--QH"
      },
      "outputs": [],
      "source": [
        "tl_model.get_layer('efficientnetv2-m').trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NABidJWfBfxX",
        "outputId": "65f21737-909f-4ef9-8101-03105879146c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"V2B3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " augmentation (Sequential)   (None, 96, 96, 3)         0         \n",
            "                                                                 \n",
            " efficientnetv2-m (Function  (None, 1280)              53150388  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 16)                20496     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 16)                64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53170982 (202.83 MB)\n",
            "Trainable params: 52878918 (201.72 MB)\n",
            "Non-trainable params: 292064 (1.11 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "N = 340\n",
        "#for i, layer in enumerate(tl_model.get_layer('efficientnetv2-b3').layers[:N]):\n",
        "#  layer.trainable=False\n",
        "tl_model.summary()\n",
        "tl_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-6), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFhKqxdfCN5x",
        "outputId": "0d23c909-2f89-4cec-eb79-a11c91bc6cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "63/63 [==============================] - 120s 278ms/step - loss: 0.5444 - accuracy: 0.7291 - val_loss: 0.4982 - val_accuracy: 0.7964 - lr: 1.0000e-06\n",
            "Epoch 2/300\n",
            "63/63 [==============================] - 12s 194ms/step - loss: 0.5286 - accuracy: 0.7369 - val_loss: 0.4901 - val_accuracy: 0.8044 - lr: 1.0000e-06\n",
            "Epoch 3/300\n",
            "63/63 [==============================] - 12s 194ms/step - loss: 0.5301 - accuracy: 0.7414 - val_loss: 0.4798 - val_accuracy: 0.8064 - lr: 1.0000e-06\n",
            "Epoch 4/300\n",
            "63/63 [==============================] - 12s 194ms/step - loss: 0.5332 - accuracy: 0.7334 - val_loss: 0.4706 - val_accuracy: 0.8144 - lr: 1.0000e-06\n",
            "Epoch 5/300\n",
            "63/63 [==============================] - 12s 189ms/step - loss: 0.5091 - accuracy: 0.7471 - val_loss: 0.4666 - val_accuracy: 0.7924 - lr: 1.0000e-06\n",
            "Epoch 6/300\n",
            "63/63 [==============================] - 12s 194ms/step - loss: 0.5020 - accuracy: 0.7536 - val_loss: 0.4650 - val_accuracy: 0.8164 - lr: 1.0000e-06\n",
            "Epoch 7/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.4985 - accuracy: 0.7656 - val_loss: 0.4538 - val_accuracy: 0.8204 - lr: 1.0000e-06\n",
            "Epoch 8/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4899 - accuracy: 0.7646 - val_loss: 0.4455 - val_accuracy: 0.8164 - lr: 1.0000e-06\n",
            "Epoch 9/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4900 - accuracy: 0.7649 - val_loss: 0.4507 - val_accuracy: 0.8204 - lr: 1.0000e-06\n",
            "Epoch 10/300\n",
            "63/63 [==============================] - 12s 197ms/step - loss: 0.4879 - accuracy: 0.7739 - val_loss: 0.4435 - val_accuracy: 0.8343 - lr: 1.0000e-06\n",
            "Epoch 11/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4812 - accuracy: 0.7736 - val_loss: 0.4386 - val_accuracy: 0.8383 - lr: 1.0000e-06\n",
            "Epoch 12/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4700 - accuracy: 0.7861 - val_loss: 0.4338 - val_accuracy: 0.8244 - lr: 1.0000e-06\n",
            "Epoch 13/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4711 - accuracy: 0.7901 - val_loss: 0.4322 - val_accuracy: 0.8323 - lr: 1.0000e-06\n",
            "Epoch 14/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4619 - accuracy: 0.7919 - val_loss: 0.4244 - val_accuracy: 0.8383 - lr: 1.0000e-06\n",
            "Epoch 15/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4614 - accuracy: 0.7991 - val_loss: 0.4209 - val_accuracy: 0.8343 - lr: 1.0000e-06\n",
            "Epoch 16/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4606 - accuracy: 0.8033 - val_loss: 0.4248 - val_accuracy: 0.8283 - lr: 1.0000e-06\n",
            "Epoch 17/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4592 - accuracy: 0.7989 - val_loss: 0.4162 - val_accuracy: 0.8323 - lr: 1.0000e-06\n",
            "Epoch 18/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4510 - accuracy: 0.8026 - val_loss: 0.4136 - val_accuracy: 0.8363 - lr: 1.0000e-06\n",
            "Epoch 19/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4473 - accuracy: 0.8088 - val_loss: 0.4087 - val_accuracy: 0.8343 - lr: 1.0000e-06\n",
            "Epoch 20/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4544 - accuracy: 0.7986 - val_loss: 0.4097 - val_accuracy: 0.8343 - lr: 1.0000e-06\n",
            "Epoch 21/300\n",
            "63/63 [==============================] - 12s 189ms/step - loss: 0.4481 - accuracy: 0.8086 - val_loss: 0.4104 - val_accuracy: 0.8343 - lr: 1.0000e-06\n",
            "Epoch 22/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4320 - accuracy: 0.8218 - val_loss: 0.4029 - val_accuracy: 0.8363 - lr: 1.0000e-06\n",
            "Epoch 23/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4401 - accuracy: 0.8128 - val_loss: 0.4019 - val_accuracy: 0.8403 - lr: 1.0000e-06\n",
            "Epoch 24/300\n",
            "63/63 [==============================] - 12s 189ms/step - loss: 0.4364 - accuracy: 0.8216 - val_loss: 0.4002 - val_accuracy: 0.8383 - lr: 1.0000e-06\n",
            "Epoch 25/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4393 - accuracy: 0.8191 - val_loss: 0.3980 - val_accuracy: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 26/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4330 - accuracy: 0.8156 - val_loss: 0.3971 - val_accuracy: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 27/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4319 - accuracy: 0.8226 - val_loss: 0.3942 - val_accuracy: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 28/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4267 - accuracy: 0.8291 - val_loss: 0.3924 - val_accuracy: 0.8543 - lr: 1.0000e-06\n",
            "Epoch 29/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.4268 - accuracy: 0.8271 - val_loss: 0.3905 - val_accuracy: 0.8523 - lr: 1.0000e-06\n",
            "Epoch 30/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4154 - accuracy: 0.8373 - val_loss: 0.3866 - val_accuracy: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 31/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.4153 - accuracy: 0.8336 - val_loss: 0.3839 - val_accuracy: 0.8483 - lr: 1.0000e-06\n",
            "Epoch 32/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4141 - accuracy: 0.8351 - val_loss: 0.3849 - val_accuracy: 0.8503 - lr: 1.0000e-06\n",
            "Epoch 33/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4142 - accuracy: 0.8303 - val_loss: 0.3832 - val_accuracy: 0.8503 - lr: 1.0000e-06\n",
            "Epoch 34/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.4118 - accuracy: 0.8366 - val_loss: 0.3797 - val_accuracy: 0.8623 - lr: 1.0000e-06\n",
            "Epoch 35/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4045 - accuracy: 0.8421 - val_loss: 0.3777 - val_accuracy: 0.8503 - lr: 1.0000e-06\n",
            "Epoch 36/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4093 - accuracy: 0.8411 - val_loss: 0.3775 - val_accuracy: 0.8583 - lr: 1.0000e-06\n",
            "Epoch 37/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3953 - accuracy: 0.8553 - val_loss: 0.3755 - val_accuracy: 0.8623 - lr: 1.0000e-06\n",
            "Epoch 38/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.4074 - accuracy: 0.8438 - val_loss: 0.3762 - val_accuracy: 0.8583 - lr: 1.0000e-06\n",
            "Epoch 39/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3977 - accuracy: 0.8491 - val_loss: 0.3721 - val_accuracy: 0.8623 - lr: 1.0000e-06\n",
            "Epoch 40/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3894 - accuracy: 0.8518 - val_loss: 0.3700 - val_accuracy: 0.8603 - lr: 1.0000e-06\n",
            "Epoch 41/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3906 - accuracy: 0.8468 - val_loss: 0.3676 - val_accuracy: 0.8603 - lr: 1.0000e-06\n",
            "Epoch 42/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3936 - accuracy: 0.8536 - val_loss: 0.3641 - val_accuracy: 0.8603 - lr: 1.0000e-06\n",
            "Epoch 43/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3897 - accuracy: 0.8538 - val_loss: 0.3688 - val_accuracy: 0.8643 - lr: 1.0000e-06\n",
            "Epoch 44/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3868 - accuracy: 0.8583 - val_loss: 0.3640 - val_accuracy: 0.8603 - lr: 1.0000e-06\n",
            "Epoch 45/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3841 - accuracy: 0.8531 - val_loss: 0.3592 - val_accuracy: 0.8663 - lr: 1.0000e-06\n",
            "Epoch 46/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3865 - accuracy: 0.8531 - val_loss: 0.3629 - val_accuracy: 0.8643 - lr: 1.0000e-06\n",
            "Epoch 47/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3805 - accuracy: 0.8631 - val_loss: 0.3591 - val_accuracy: 0.8703 - lr: 1.0000e-06\n",
            "Epoch 48/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3786 - accuracy: 0.8608 - val_loss: 0.3565 - val_accuracy: 0.8683 - lr: 1.0000e-06\n",
            "Epoch 49/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3779 - accuracy: 0.8668 - val_loss: 0.3516 - val_accuracy: 0.8723 - lr: 1.0000e-06\n",
            "Epoch 50/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3716 - accuracy: 0.8671 - val_loss: 0.3562 - val_accuracy: 0.8643 - lr: 1.0000e-06\n",
            "Epoch 51/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3762 - accuracy: 0.8623 - val_loss: 0.3538 - val_accuracy: 0.8663 - lr: 1.0000e-06\n",
            "Epoch 52/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.3681 - accuracy: 0.8663 - val_loss: 0.3518 - val_accuracy: 0.8663 - lr: 1.0000e-06\n",
            "Epoch 53/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.3724 - accuracy: 0.8623 - val_loss: 0.3552 - val_accuracy: 0.8603 - lr: 1.0000e-06\n",
            "Epoch 54/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.3701 - accuracy: 0.8686 - val_loss: 0.3516 - val_accuracy: 0.8703 - lr: 1.0000e-06\n",
            "Epoch 55/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3711 - accuracy: 0.8731 - val_loss: 0.3547 - val_accuracy: 0.8762 - lr: 1.0000e-06\n",
            "Epoch 56/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.3641 - accuracy: 0.8688 - val_loss: 0.3528 - val_accuracy: 0.8623 - lr: 1.0000e-06\n",
            "Epoch 57/300\n",
            "63/63 [==============================] - 12s 193ms/step - loss: 0.3627 - accuracy: 0.8753 - val_loss: 0.3489 - val_accuracy: 0.8762 - lr: 1.0000e-06\n",
            "Epoch 58/300\n",
            "63/63 [==============================] - 12s 193ms/step - loss: 0.3625 - accuracy: 0.8723 - val_loss: 0.3541 - val_accuracy: 0.8762 - lr: 1.0000e-06\n",
            "Epoch 59/300\n",
            "63/63 [==============================] - 12s 192ms/step - loss: 0.3629 - accuracy: 0.8753 - val_loss: 0.3523 - val_accuracy: 0.8703 - lr: 1.0000e-06\n",
            "Epoch 60/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3620 - accuracy: 0.8786 - val_loss: 0.3472 - val_accuracy: 0.8782 - lr: 1.0000e-06\n",
            "Epoch 61/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3582 - accuracy: 0.8761 - val_loss: 0.3455 - val_accuracy: 0.8743 - lr: 1.0000e-06\n",
            "Epoch 62/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3501 - accuracy: 0.8818 - val_loss: 0.3451 - val_accuracy: 0.8782 - lr: 1.0000e-06\n",
            "Epoch 63/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3523 - accuracy: 0.8808 - val_loss: 0.3463 - val_accuracy: 0.8683 - lr: 1.0000e-06\n",
            "Epoch 64/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3570 - accuracy: 0.8763 - val_loss: 0.3488 - val_accuracy: 0.8703 - lr: 1.0000e-06\n",
            "Epoch 65/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3489 - accuracy: 0.8813 - val_loss: 0.3440 - val_accuracy: 0.8782 - lr: 1.0000e-06\n",
            "Epoch 66/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3488 - accuracy: 0.8913 - val_loss: 0.3457 - val_accuracy: 0.8802 - lr: 1.0000e-06\n",
            "Epoch 67/300\n",
            "63/63 [==============================] - 12s 196ms/step - loss: 0.3479 - accuracy: 0.8846 - val_loss: 0.3417 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
            "Epoch 68/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3410 - accuracy: 0.8908 - val_loss: 0.3460 - val_accuracy: 0.8782 - lr: 1.0000e-06\n",
            "Epoch 69/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3451 - accuracy: 0.8913 - val_loss: 0.3446 - val_accuracy: 0.8822 - lr: 1.0000e-06\n",
            "Epoch 70/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3407 - accuracy: 0.8938 - val_loss: 0.3475 - val_accuracy: 0.8723 - lr: 1.0000e-06\n",
            "Epoch 71/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3433 - accuracy: 0.8863 - val_loss: 0.3414 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
            "Epoch 72/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3404 - accuracy: 0.8926 - val_loss: 0.3460 - val_accuracy: 0.8762 - lr: 1.0000e-06\n",
            "Epoch 73/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3422 - accuracy: 0.8881 - val_loss: 0.3351 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 74/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3355 - accuracy: 0.8921 - val_loss: 0.3422 - val_accuracy: 0.8822 - lr: 1.0000e-06\n",
            "Epoch 75/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3420 - accuracy: 0.8911 - val_loss: 0.3321 - val_accuracy: 0.8982 - lr: 1.0000e-06\n",
            "Epoch 76/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3406 - accuracy: 0.8891 - val_loss: 0.3320 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 77/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3342 - accuracy: 0.8951 - val_loss: 0.3398 - val_accuracy: 0.8802 - lr: 1.0000e-06\n",
            "Epoch 78/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3330 - accuracy: 0.8953 - val_loss: 0.3363 - val_accuracy: 0.8902 - lr: 1.0000e-06\n",
            "Epoch 79/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3284 - accuracy: 0.9018 - val_loss: 0.3389 - val_accuracy: 0.8822 - lr: 1.0000e-06\n",
            "Epoch 80/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3312 - accuracy: 0.9000 - val_loss: 0.3404 - val_accuracy: 0.8822 - lr: 1.0000e-06\n",
            "Epoch 81/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3355 - accuracy: 0.8968 - val_loss: 0.3394 - val_accuracy: 0.8822 - lr: 1.0000e-06\n",
            "Epoch 82/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3318 - accuracy: 0.9038 - val_loss: 0.3321 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 83/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3274 - accuracy: 0.8981 - val_loss: 0.3293 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 84/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3240 - accuracy: 0.9045 - val_loss: 0.3298 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
            "Epoch 85/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3256 - accuracy: 0.9013 - val_loss: 0.3341 - val_accuracy: 0.8902 - lr: 1.0000e-06\n",
            "Epoch 86/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3225 - accuracy: 0.9010 - val_loss: 0.3365 - val_accuracy: 0.8782 - lr: 1.0000e-06\n",
            "Epoch 87/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3186 - accuracy: 0.9065 - val_loss: 0.3330 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
            "Epoch 88/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3206 - accuracy: 0.9075 - val_loss: 0.3325 - val_accuracy: 0.8862 - lr: 1.0000e-06\n",
            "Epoch 89/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3274 - accuracy: 0.8976 - val_loss: 0.3268 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
            "Epoch 90/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3218 - accuracy: 0.8998 - val_loss: 0.3267 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 91/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3194 - accuracy: 0.9083 - val_loss: 0.3252 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 92/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3160 - accuracy: 0.9120 - val_loss: 0.3311 - val_accuracy: 0.8902 - lr: 1.0000e-06\n",
            "Epoch 93/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3151 - accuracy: 0.9125 - val_loss: 0.3316 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 94/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3131 - accuracy: 0.9155 - val_loss: 0.3256 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 95/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3200 - accuracy: 0.9073 - val_loss: 0.3197 - val_accuracy: 0.9102 - lr: 1.0000e-06\n",
            "Epoch 96/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3167 - accuracy: 0.9093 - val_loss: 0.3266 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 97/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3104 - accuracy: 0.9108 - val_loss: 0.3202 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
            "Epoch 98/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3155 - accuracy: 0.9090 - val_loss: 0.3294 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 99/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3101 - accuracy: 0.9208 - val_loss: 0.3232 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 100/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3052 - accuracy: 0.9173 - val_loss: 0.3195 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
            "Epoch 101/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3127 - accuracy: 0.9100 - val_loss: 0.3195 - val_accuracy: 0.9002 - lr: 1.0000e-06\n",
            "Epoch 102/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3048 - accuracy: 0.9180 - val_loss: 0.3261 - val_accuracy: 0.8902 - lr: 1.0000e-06\n",
            "Epoch 103/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3127 - accuracy: 0.9150 - val_loss: 0.3138 - val_accuracy: 0.9042 - lr: 1.0000e-06\n",
            "Epoch 104/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3053 - accuracy: 0.9195 - val_loss: 0.3262 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 105/300\n",
            "63/63 [==============================] - 12s 195ms/step - loss: 0.3075 - accuracy: 0.9140 - val_loss: 0.3109 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
            "Epoch 106/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3032 - accuracy: 0.9193 - val_loss: 0.3221 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
            "Epoch 107/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.2967 - accuracy: 0.9225 - val_loss: 0.3146 - val_accuracy: 0.9082 - lr: 1.0000e-06\n",
            "Epoch 108/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3071 - accuracy: 0.9138 - val_loss: 0.3153 - val_accuracy: 0.9102 - lr: 1.0000e-06\n",
            "Epoch 109/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.3122 - accuracy: 0.9118 - val_loss: 0.3187 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 110/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3026 - accuracy: 0.9198 - val_loss: 0.3165 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
            "Epoch 111/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2996 - accuracy: 0.9243 - val_loss: 0.3192 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 112/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.3002 - accuracy: 0.9238 - val_loss: 0.3248 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 113/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.2996 - accuracy: 0.9218 - val_loss: 0.3215 - val_accuracy: 0.9002 - lr: 1.0000e-06\n",
            "Epoch 114/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2932 - accuracy: 0.9275 - val_loss: 0.3214 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 115/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2924 - accuracy: 0.9275 - val_loss: 0.3153 - val_accuracy: 0.9082 - lr: 1.0000e-06\n",
            "Epoch 116/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2961 - accuracy: 0.9230 - val_loss: 0.3145 - val_accuracy: 0.9002 - lr: 1.0000e-06\n",
            "Epoch 117/300\n",
            "63/63 [==============================] - 12s 191ms/step - loss: 0.2901 - accuracy: 0.9283 - val_loss: 0.3122 - val_accuracy: 0.9042 - lr: 1.0000e-06\n",
            "Epoch 118/300\n",
            "63/63 [==============================] - 12s 189ms/step - loss: 0.2992 - accuracy: 0.9210 - val_loss: 0.3206 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 119/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2991 - accuracy: 0.9240 - val_loss: 0.3141 - val_accuracy: 0.8962 - lr: 1.0000e-06\n",
            "Epoch 120/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2910 - accuracy: 0.9270 - val_loss: 0.3216 - val_accuracy: 0.9002 - lr: 1.0000e-06\n",
            "Epoch 121/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2891 - accuracy: 0.9325 - val_loss: 0.3146 - val_accuracy: 0.8982 - lr: 1.0000e-06\n",
            "Epoch 122/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2901 - accuracy: 0.9298 - val_loss: 0.3211 - val_accuracy: 0.8922 - lr: 1.0000e-06\n",
            "Epoch 123/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2909 - accuracy: 0.9340 - val_loss: 0.3063 - val_accuracy: 0.9102 - lr: 1.0000e-06\n",
            "Epoch 124/300\n",
            "63/63 [==============================] - 12s 190ms/step - loss: 0.2966 - accuracy: 0.9270 - val_loss: 0.3142 - val_accuracy: 0.8982 - lr: 1.0000e-06\n",
            "Epoch 125/300\n",
            "63/63 [==============================] - 12s 197ms/step - loss: 0.2934 - accuracy: 0.9275 - val_loss: 0.3134 - val_accuracy: 0.8982 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "history = tl_model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-RDQJetwVwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "417afac7-5b3b-4c63-b8e7-96f272fc85bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions Shape: (501, 2)\n",
            "Accuracy: 0.9002\n",
            "Precision: 0.9057\n",
            "Recall: 0.8822\n",
            "F1: 0.8913\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions = tl_model.predict(X_test, verbose=0)\n",
        "print(\"Predictions Shape:\", predictions.shape)\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1))\n",
        "\n",
        "# Compute classification metrics\n",
        "accuracy = accuracy_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1))\n",
        "precision = precision_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "recall = recall_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "f1 = f1_score(np.argmax(y_test.values, axis=1), np.argmax(predictions, axis=1), average='macro')\n",
        "\n",
        "# Display the computed metrics\n",
        "print('Accuracy:', accuracy.round(4))\n",
        "print('Precision:', precision.round(4))\n",
        "print('Recall:', recall.round(4))\n",
        "print('F1:', f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm.T, xticklabels={0, 1}, yticklabels={0, 1}, cmap='Blues')\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIuGq0zq7E94"
      },
      "outputs": [],
      "source": [
        "tl_model.save('V2M_1.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}